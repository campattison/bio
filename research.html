<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Research - Cameron Pattison</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
</head>
<body>
    <div class="container">
        <header>
            <nav class="main-nav">
                <a href="index.html">Home</a>
                <a href="research.html" class="active">Research</a>
                <a href="teaching.html">Teaching</a>
                <a href="ai-tools.html">AI Tools</a>
                <a href="https://philosophyofcomputing.substack.com" target="_blank" rel="noopener noreferrer">Newsletter</a>
            </nav>
            <h1>Research</h1>
        </header>

        <section class="research-areas">
            <h2>Research Areas</h2>
            <ul>
                <li><i class="fas fa-brain"></i> AI Ethics and Philosophy of Mind</li>
                <li><i class="fas fa-balance-scale"></i> Justice and Fairness in AI Systems</li>
                <li><i class="fas fa-robot"></i> Machine Learning Interpretability</li>
                <li><i class="fas fa-users"></i> Human-AI Interaction</li>
            </ul>
        </section>

        <section class="current-projects">
            <h2>Current Projects</h2>
            <ul>
                <li><i class="fas fa-microscope"></i> Investigating AI's Impact on Scientific Discovery</li>
                <li><i class="fas fa-graduation-cap"></i> AI in Education and Learning</li>
                <li><i class="fas fa-chart-line"></i> Measuring AI Progress and Capabilities</li>
            </ul>
        </section>

        <section class="research-journey">
            <h2>Research Journey</h2>
            <div class="timeline">
                <div class="timeline-item">
                    <h3>Classical Foundations</h3>
                    <p>My research began with questions about cognition and reason in the Aristotelian tradition and its development in the Islamic philosophical world, examining how premodern thinkers grappled with rationality, perception, and human nature.</p>
                </div>
                <div class="timeline-item">
                    <h3>Bridge to Contemporary Questions</h3>
                    <p>This historical investigation led to deeper questions about what cognition means—human or otherwise—and how these classical frameworks can inform our understanding of artificial intelligence.</p>
                </div>
                <div class="timeline-item">
                    <h3>Current Focus</h3>
                    <p>Working at the intersection of classical philosophy and AI ethics, exploring how historical philosophical frameworks can help us navigate questions of moral agency, rationality, and intelligence in artificial systems.</p>
                </div>
            </div>
        </section>

        <section class="publications">
            <h2>Current Projects</h2>
            <div class="research-card">
                <h3>AI Reasoning and the Taking Condition</h3>
                <p><strong>Author:</strong> Cameron Pattison</p>
                <p><strong>Affiliation:</strong> Vanderbilt</p>
                <p><strong>Email:</strong> cameron.pattison@vanderbilt.edu</p>
                <p><strong>Keywords:</strong> Inference, Artificial Intelligence, Reasoning, Taking Condition</p>
                <p><strong>Abstract:</strong> In recent years, philosophers have defined 'reasoning' as a process subject to a <em>Taking Condition</em>: Reasoners must <em>take</em> their premises as support for their conclusions. This paper argues that this condition inadvertently excludes both Artificial Intelligence (AI) and human cognition from the category of 'reasoning'. First, I show that neither symbolic AI nor large language models satisfy the <em>Taking Condition</em>, despite their ability to produce logically valid inferences. Second, drawing on evidence from neuroscience and cognitive psychology, I argue that human cognition likely operates on similar principles to AI, particularly in its reliance on pattern recognition and statistical learning. If this isomorphism holds, it suggests that humans may also fail to satisfy the <em>Taking Condition</em>. This leads to the problematic conclusion that, under the current definition, nothing 'reasons'. To resolve this issue, I propose that we need to reconsider our definition of reasoning, particularly the centrality of the <em>Taking Condition</em>.</p>
            </div>
            <div class="research-card">
                <h3>Revelation in al-Fārābī's Virtuous City</h3>
                <p><strong>Author:</strong> Cameron Pattison</p>
                <p><strong>Affiliation:</strong> Vanderbilt</p>
                <p><strong>Email:</strong> cameron.pattison@vanderbilt.edu</p>
                <p><strong>Abstract:</strong> This chapter offers a comprehensive analysis of al-Fārābī's treatment of revelation in his Mabādi' Ārā' Ahl al-Madīnat al-Fāḍilah (The Principles of the Opinions of the People of the Virtuous City). It explores the structure of his theory, its philosophical origins, and its integration with other aspects of his thought. By exploring the connections between his psychological theory and broader metaphysical commitments, the study demonstrates how al-Fārābī adapts and refines Aristotelian and Neoplatonic ideas to construct a systematic account of revelation. It first provides the reader with a working understanding of al-Fārābī’s theory of revelation as it is presented in the Mabādi'. It then places this theory among its sources, especially those texts and recensions that have been recently proposed as the foundations of al-Fārābī’s doctrine. It concludes by addressing the gaps in these sources, arguing that al-Fārābī’s pedagogical theory provides a unique resolution to this incompleteness, showcasing his innovative synthesis of inherited traditions.</p>
            </div>
        </section>
    </div>
</body>
</html> 